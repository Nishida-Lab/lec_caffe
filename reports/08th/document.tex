\documentclass[a4paper,10pt]{jsarticle}

% レイアウト
\setlength{\textwidth}{\fullwidth}
\setlength{\textheight}{39\baselineskip}
\addtolength{\textheight}{\topskip}
\setlength{\voffset}{-0.5in}
\setlength{\headsep}{0.3in}
\pagestyle{myheadings}

% パッケージ
\usepackage[dvipdfmx]{graphicx}
\usepackage{amsmath,amssymb,epsfig}
\usepackage{bm}
\usepackage{ascmac}
\usepackage{pifont}
\usepackage{multirow}
\usepackage{enumerate}
\usepackage{cases}
\usepackage{type1cm}
\usepackage{cancel}
\usepackage{url}
\usepackage{color}
\usepackage{listings,jlisting}
% 大きな中括弧
\usepackage{cases}

% 定義
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\def\vec#1{\mbox{\boldmath$#1$}}
\def\R{{\Bbb R}}

% カウンタの設定
\setcounter{section}{0}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{equation}{0}

% キャプションの図をFigに変更
\renewcommand{\figurename}{Fig.}
\renewcommand{\tablename}{Tab.}

% 式番号を式(章番号.番号)に
% \makeatletter
% \renewcommand{\theequation}{\arabic{section}.\arabic{equation}}
% \@addtoreset{equation}{section}
% \makeatother

% プログラムに色をつける
\usepackage{color}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}

\lstset{style=mystyle}

% 表紙
\title{知能システム学特論レポート}
\author{
（DL2班）Caffe on Ubuntu\\
}
\date{2015年\ 7月\ 13日}

% ドキュメントの開始
\begin{document}
\maketitle
\section{報告者}
\begin{list}{}{}
 \item 15344203\hspace{0.5cm} 有田 裕太
 \item 15344206\hspace{0.5cm} 緒形 裕太
 \item 15344209\hspace{0.5cm} 株丹 亮
 \item 12104125\hspace{0.5cm} 宮本 和
\end{list}

\section{進行状況}

\begin{itemize}
\item 畳み込みネットワークと正規化層の理論について
\item データセットの作成準備
\end{itemize}

\section{理論研究}

\subsection{局所コントラスト正規化層}

我々人間は,画像の明るさやコントラストの違いにさほど気をとられることなく,画像に写るものに意識を向けることができる.生物の視覚系にはこれらの違いをうまく調節する機能があるためである.これに対応して,画像の濃淡をなんらかの方法で正規化する必要がある.
その方法に局所コントラスト正規化があり,画像1枚1枚に対し個別に行う処理のことである.これは畳み込みネットに固有の処理ではなく,一般的な画像処理の1つだが,畳み込みやプーリングと同様,1つの層でこの処理を実行できる。誤差逆伝播計算も可能であり,畳み込みネットに組み込むことができる.また、プーリング層と同様,この層の重みは固定され,学習の対象となるパラネータはない.
そして,局所コントラスト正規化には減算正規化と除算正規化の２つがある.

\subsection{単一チャネルの正規化}
単一チャネルの画像$x_{ij}$に対し，プーリングと同様，画素$(i,j)$を中心と
する$H\times H$の正方領域$P_{ij}$を考える．減算正規化とは，入力画像の各
画素濃淡から，$P_{ij}$に含まれる画素の濃淡の平均，つまり
$\bar{x}_{ij}= \sum_{(p,q)\in{P_{ij}}}^{} x_{i+p,j+q}$を差し引く．
\begin{equation}
 z_{ij} = x_{ij}-\bar{x}_{ij}
\end{equation}
ここで差し引く$\bar{x}_{ij}$には，重み付き平均
\begin{equation}
 \bar{x}_{ij}=\sum_{(p,q)\in{P_{ij}}} w_{pq}x_{i+p,j+q}
\end{equation}
を使う場合もある．その場合$w_{pq}$は
\begin{equation}
  \sum_{(p,q)\in{P_{ij}}}^{} w_{pq} = \sum_{q=0}^{H-1} \sum_{q=0}^{H-1} w_{pq}=1
\end{equation}
であり，領域の中央で最大値をとり，周辺部へ向けて低下するようなものとする．
領域の中央部をより重視し，周辺部の相対的な影響を少なくるためである．

同じ領域内で，さらに画素値の分散を抑える操作が除算正規化である．$P_{ij}$
内の画素値の分散は
\begin{equation}
 \sigma^2_{ij}=\sum_{(p,q)\in{P_{ij}}}^{} w_{pq}(x_{i+p,j+q}-\bar{x}_{ij})^2
\end{equation}
となるが，減算正規化を施した入力画像をこの標準偏差で割る．
\begin{equation}
 z_{ij}=\frac{x_{ij}-\bar{x}_{ij}}{\sigma_{ij}}
\end{equation}
この計算をそのまま行うと，濃淡変化が少ない局所領域ほど濃淡変化が増幅され，
ノイズが強調される．そこで，入力画像のコントラストが大きい部分にのみ適用
するために，ある定数$c$を設定し，濃淡の標準偏差がこれを下回る
($\sigma_{ij}<c$)で除算する
\begin{equation}
 z_{ij}=\frac{x_{ij}-\bar{x}_{ij}}{max(\sigma_{ij}<c)}
\end{equation}
や，同様の効果が$\sigma_{ij}$に応じて連続的に変化する
\begin{equation}
 z_{ij}=\frac{x_{ij}-\bar{x}_{ij}}{\sqrt{\sigma_{ij}+c}}
\end{equation}
を使う．% 減算正規化および式\ref{}による除算正規化の計算例を図
% \ref{}に示す．
% これらの正規化の結果，画像の画素値は負の値をとり得るため，画素値の最大値
% と最小値が[0,255]の範囲に収まるように画素値を線形変換している.

\subsection{多チャネル画像の正規化}
多チャネル画像では，単一チャネルごとの正規化を適応することもできるが，一
般的にはチャネル間の相互作用を考える．その場合，画素値の平均と分散を求め
る対象が全チャネルにわたる局所領域$P_{ij}$内の画素の集合に代わる．$K$チャ
ネルからなる画像$x_{ijk}$を対象とするとき，重み付き平均を
\begin{equation}
 \bar{x}_{ij}=\frac{1}{K}\sum_{k=0}{K-1}\sum{(p,q)\in{P_{ij}}}{} w_{pq}x_{i+p,j+q,k}
\end{equation}
のように決定します．減算正規化は，画素$(i,j)$ごとに違うがチャネル間では
共通の$\bar{x}_ij$を差し引いて
\begin{equation}
 z_{ijk}=x_{ijk}-\bar{x}_{ij}
\end{equation}
のように行われる．画像の全チャネルにわたる$P_{ij}$の分散は
\begin{equation}
  \omega^2_{ij}=\frac{1}{K}\sum_{k=0}{K-1}\sum_{(p,q)\in{P_{ij}}}^{} w_{pqk}(x_{i+p,j+q,k}-\bar{x}_{ij})^2
\end{equation}
のように計算され，除算正規化は
\begin{equation}
  z_{ijk}=\frac{x_{ijk}-\bar{x}_{ij}}{max(\sigma_{ij},c)}
\end{equation}
となる．単一チャネルの場合と同様に，分母を$\sqrt{c+\sigma^2_{ij}}$とする
こともできる．


\section{プログラミング}
\subsection{画像を学習させて分類器を作るまでの流れ}
データセットを作成し，学習を行ってモデルを作成するまでの流れをFig.~\ref{fig:モデルを作成するまでの流れ}に示す．
Fig.~\ref{fig:モデルを作成するまでの流れ}より(1)の大量の写真データまたは動画からの切り出しに関しては前回の発表で述べた手法，作成したプログラムによって顔のみを切り出した画像ファイルを作成する．
\begin{figure}[tb]
  \begin{center}
    \includegraphics[clip,width=6cm]{fig/eps/learning_flow.eps}
  \end{center}
  \caption{モデルを作成するまでの流れ}
  \label{fig:モデルを作成するまでの流れ}
\end{figure}

\subsection{切り出した画像からキャラクターごとにクラスタリングを行う}
Fig.~\ref{fig:モデルを作成するまでの流れ}より(2)の作業は(1)で生成された顔画像をそれぞれの人物，キャラクターごとにクラス分けする作業である．
各画像はラベル名のディレクトリに入れ，ラベル名のディレクトリはこのように（0/ 1/ 2/...）数字にしておく．
この数字とラベル名の関連付けは実際に画像を分類する際に必要なので記録しておく．

\subsection{画像の正規化}
Fig.~\ref{fig:モデルを作成するまでの流れ}の(3)で，生成した画像を正規化する．
正規化の処理はImageMagickを用いた．
クラスタリングした各ディレクトリで以下のコマンドを実行する．

\begin{lstlisting}[basicstyle=\ttfamily\footnotesize, frame=single, firstnumber=1, numbers=left, breaklines=true]
for file in `ls`; do convert ${file} -equalize ${file}; done
\end{lstlisting}

\subsection{LevelDBデータセットの作成}
用意した画像をCaffeで読み込むLevelDBと呼ばれる形式に変換する必要がある．
変換スクリプトはSIG2D\cite{SIG2D}に掲載されているものを使用した．
このスクリプトによって全入力画像から9割を訓練データ，1割をテストデータに割り振ることができる．

\subsection{平均画像の作成}
平均画像を作成するために以下のコマンドを実行する．保存名はmean.binaryprotoである．
\begin{lstlisting}[basicstyle=\ttfamily\footnotesize, frame=single, firstnumber=1, numbers=left, breaklines=true]
build/tools/compute_image_mean.bin -backend=leveldb ./examples/cifar10/cifar10_train_leveldb ./examples/cifar10/mean.binaryproto
\end{lstlisting}

\subsection{学習機の設定}
今回は基本的にはcifer10の学習器をそのまま使用した．
ただし，最終的な出力は対象とするものによって数が変わるため，変更を行った．
変更するファイルはcifar10\_quick\_train\_test.prototxtとcifar10\_quick.prototxtである．

\begin{lstlisting}[basicstyle=\ttfamily\footnotesize, frame=single, firstnumber=1, numbers=left, breaklines=true]
layers {
  name: "ip2"
  type: INNER_PRODUCT
  bottom: "ip1"
  top: "ip2"
  blobs_lr: 1
  blobs_lr: 2
  inner_product_param {
    num_output: 10      ここを変更
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
\end{lstlisting}

\subsection{学習の実行}
以下のコマンドによって学習を実行する．
学習は前回発表したように，GPUを用いて行った．
GPUを用いる場合，標準設定がGPUで行うように設定してあるので，ファイルの記述を変更する必要はない．
CPUのみを用いる場合，cifar10\_full\_solver.prototxtを最後の行にあるsolver\_mode: GPUをCPUに変更する．

\begin{lstlisting}[basicstyle=\ttfamily\footnotesize, frame=single, firstnumber=1, numbers=left, breaklines=true]
caffe train --solver examples/cifar10/cifar10_quick_solver.prototxt
\end{lstlisting}

学習が完了すると，cifar10\_quick\_iter\_4000.caffemodelというファイルが生成される．

\section{今後の課題}
\begin{itemize}
 \item 理論研究を進める．
 \item データセットの作成，学習実行結果の評価と過程の可視化．
\end{itemize}


%% 文献
\begin{thebibliography}{99}
  \bibitem{SIG2D} SIG2D，``SIG2D' 14 Proceedings of the 3rd Interdimensional Conference on 2D Information Processing ''，\url{http://sig2d.org/publications/}，2014．
\end{thebibliography}

\end{document}